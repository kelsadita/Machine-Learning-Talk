{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "--- \n",
    "<p>What you might have to do before using a learner in `sklearn`:</p>\n",
    "* Non-numerics transformed to numeric (tip: use applymap() method from `pandas`)\n",
    "* Fill in missing values\n",
    "* Standardization\n",
    "* Normalization\n",
    "* Encoding categorical features (e.g. one-hot encoding or dummy variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why Standardization and Normalization is required?\n",
    "- Common requirement for many machine learning estimators\n",
    "- They might behave badly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.032057</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.143017</td>\n",
       "      <td>-0.124958</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.385353</td>\n",
       "      <td>0.337848</td>\n",
       "      <td>-1.398138</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.506521</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>-1.284407</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.021849</td>\n",
       "      <td>1.263460</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0 -0.900681  1.032057 -1.341272 -1.312977\n",
       "1 -1.143017 -0.124958 -1.341272 -1.312977\n",
       "2 -1.385353  0.337848 -1.398138 -1.312977\n",
       "3 -1.506521  0.106445 -1.284407 -1.312977\n",
       "4 -1.021849  1.263460 -1.341272 -1.312977"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardization aka scaling\n",
    "from sklearn import preprocessing, datasets\n",
    "\n",
    "# Make sure we have iris loaded\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "\n",
    "# Data and labels (target)\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Scale it to a gaussian distribution\n",
    "X_scaled = preprocessing.scale(X)\n",
    "\n",
    "# How does it look now\n",
    "pd.DataFrame(X_scaled).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>1.500000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.690315e-15</td>\n",
       "      <td>-1.637024e-15</td>\n",
       "      <td>-1.482518e-15</td>\n",
       "      <td>-1.623146e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.003350e+00</td>\n",
       "      <td>1.003350e+00</td>\n",
       "      <td>1.003350e+00</td>\n",
       "      <td>1.003350e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.870024e+00</td>\n",
       "      <td>-2.438987e+00</td>\n",
       "      <td>-1.568735e+00</td>\n",
       "      <td>-1.444450e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-9.006812e-01</td>\n",
       "      <td>-5.877635e-01</td>\n",
       "      <td>-1.227541e+00</td>\n",
       "      <td>-1.181504e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-5.250608e-02</td>\n",
       "      <td>-1.249576e-01</td>\n",
       "      <td>3.362659e-01</td>\n",
       "      <td>1.332259e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.745011e-01</td>\n",
       "      <td>5.692513e-01</td>\n",
       "      <td>7.627586e-01</td>\n",
       "      <td>7.905908e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.492019e+00</td>\n",
       "      <td>3.114684e+00</td>\n",
       "      <td>1.786341e+00</td>\n",
       "      <td>1.710902e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3\n",
       "count  1.500000e+02  1.500000e+02  1.500000e+02  1.500000e+02\n",
       "mean  -1.690315e-15 -1.637024e-15 -1.482518e-15 -1.623146e-15\n",
       "std    1.003350e+00  1.003350e+00  1.003350e+00  1.003350e+00\n",
       "min   -1.870024e+00 -2.438987e+00 -1.568735e+00 -1.444450e+00\n",
       "25%   -9.006812e-01 -5.877635e-01 -1.227541e+00 -1.181504e+00\n",
       "50%   -5.250608e-02 -1.249576e-01  3.362659e-01  1.332259e-01\n",
       "75%    6.745011e-01  5.692513e-01  7.627586e-01  7.905908e-01\n",
       "max    2.492019e+00  3.114684e+00  1.786341e+00  1.710902e+00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's just confirm our standardization worked (mean is 0 w/ unit variance)\n",
    "pd.DataFrame(X_scaled).describe()\n",
    "\n",
    "# Also could:\n",
    "# print(X_scaled.mean(axis = 0))\n",
    "# print(X_scaled.std(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To save our standardization and reapply later (say to the test set or some new data), create a transformer object like so:\n",
    "\n",
    "```python\n",
    "\n",
    "# Standardize through scaling\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "# Apply to a new dataset (e.g. test set):\n",
    "scaler.transform(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (Clean Data) and Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the learning easier or better  beforehand -  feature reduction/selection/creation\n",
    "* SelectKBest\n",
    "* One-Hot Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting k top scoring features (also dimensionality reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Loading iris data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (150, 4)\n"
     ]
    }
   ],
   "source": [
    "# SelectKBest for selecting top-scoring features\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Our nice, clean data (it's not always going to be this easy) - what's the function to load it?\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "print('Original shape:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Adding new column to our obervations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'petal width / sepal width']\n"
     ]
    }
   ],
   "source": [
    "# Let's add a NEW feature - a ratio of two of the iris measurements.\n",
    "df = pd.DataFrame(X, columns = iris.feature_names)\n",
    "\n",
    "# New feature is petal width / sepal width\n",
    "df['petal width / sepal width'] = df['petal width (cm)'] / df['sepal width (cm)']\n",
    "\n",
    "# Grab feature names + new one\n",
    "new_feature_names = df.columns\n",
    "print('New feature names:', list(new_feature_names))\n",
    "\n",
    "# We've now added a new column to our data\n",
    "X = np.array(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Performing feature selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chi2 is the statistical test to determine the dependence between 2 variables\n",
    "# in this case its the amount of dependence between feature and target class\n",
    "dim_red = SelectKBest(chi2, k = 3)\n",
    "dim_red.fit(X, y)\n",
    "X_t = dim_red.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Show scores, features selected and new shape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [  10.81782088    3.59449902  116.16984746   67.24482759   23.61598059]\n",
      "New shape: (150, 3)\n"
     ]
    }
   ],
   "source": [
    "# Show scores, features selected and new shape\n",
    "print('Scores:', dim_red.scores_)\n",
    "print('New shape:', X_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Get back the selected columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top k features:  ['petal length (cm)', 'petal width (cm)', 'petal width / sepal width']\n"
     ]
    }
   ],
   "source": [
    "selected = dim_red.get_support() # boolean values\n",
    "selected_names = new_feature_names[selected]\n",
    "\n",
    "print('Top k features: ', list(selected_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on scoring function selection in `SelectKBest` tranformations:**\n",
    "* For regression - [f_regression](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression)\n",
    "* For classification - [chi2](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2), [f_classif](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html#sklearn.feature_selection.f_classif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More feature selection methods [here](http://scikit-learn.org/stable/modules/feature_selection.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "* It's an operation on feature labels - a method of dummying variable\n",
    "* Expands the feature space by nature of transform - later this can be processed further with a dimensionality reduction (the dummied variables are now their own features)\n",
    "* FYI:  One hot encoding variables is needed for python ML module `tenorflow`\n",
    "* Can do this with `pandas` method or a `sklearn` one-hot-encoder system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/before_one_hot_encoding.png' alt=\"Smiley face\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/after_one_hot_encoding.png' alt=\"Smiley face\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pandas` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target_name_setosa</th>\n",
       "      <th>target_name_versicolor</th>\n",
       "      <th>target_name_virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target_name_setosa  target_name_versicolor  target_name_virginica  \n",
       "0                 1.0                     0.0                    0.0  \n",
       "1                 1.0                     0.0                    0.0  \n",
       "2                 1.0                     0.0                    0.0  \n",
       "3                 1.0                     0.0                    0.0  \n",
       "4                 1.0                     0.0                    0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy variables with pandas built-in function\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Convert to dataframe and add a column with iris species name\n",
    "data = pd.DataFrame(X, columns = iris.feature_names)\n",
    "data['target_name'] = iris.target_names[y]\n",
    "\n",
    "df = pd.get_dummies(data, prefix = ['target_name'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
